{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 必要パッケージインストール"
      ],
      "metadata": {
        "id": "LwqjcLmyiky4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kornia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JniSs_KZfB11",
        "outputId": "20bef9ec-44b0-4694-e385-b4719d6f935a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kornia\n",
            "  Downloading kornia-0.6.9-py2.py3-none-any.whl (569 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m569.1/569.1 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from kornia) (21.3)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from kornia) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.9.1->kornia) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->kornia) (3.0.9)\n",
            "Installing collected packages: kornia\n",
            "Successfully installed kornia-0.6.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# インポート"
      ],
      "metadata": {
        "id": "TM4suvM4im9Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mVtCiZ-X3nro"
      },
      "outputs": [],
      "source": [
        "import kornia\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import urllib.request as request;\n",
        "\n",
        "# Load some scripts from remote.\n",
        "exec(request.urlopen('https://github.com/mingcv/Bread_Colab/raw/main/colab_utils.py').read(), globals())\n",
        "exec(request.urlopen(locate_resource('networks.py')).read(), globals())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# モデル重みダウンロード"
      ],
      "metadata": {
        "id": "n4P5feGZioxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download trained model weights from remote.\n",
        "download_url_to_file(locate_resource('checkpoints/IANet_335.pth'))\n",
        "download_url_to_file(locate_resource('checkpoints/NSNet_422.pth'))\n",
        "download_url_to_file(locate_resource('checkpoints/FuseNet_CA_MEF_251.pth'))\n",
        "download_url_to_file(locate_resource('checkpoints/FuseNet_FD_297.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiY6uCqCiWoQ",
        "outputId": "f2a6586b-49d8-4f89-a449-db1f0d672efb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.25M/3.25M [00:00<00:00, 51.9MB/s]\n",
            "100%|██████████| 3.25M/3.25M [00:00<00:00, 72.2MB/s]\n",
            "100%|██████████| 874k/874k [00:00<00:00, 28.0MB/s]\n",
            "100%|██████████| 872k/872k [00:00<00:00, 21.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# モデル定義、重み読み込み"
      ],
      "metadata": {
        "id": "-A9wttPEisYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defination of the Bread Framework.\n",
        "class ModelBreadNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-6\n",
        "        self.model_ianet = IAN(in_channels=1, out_channels=1)\n",
        "        self.model_nsnet = ANSN(in_channels=2, out_channels=1)\n",
        "        self.model_canet = FuseNet(in_channels=4, out_channels=2)\n",
        "\n",
        "        self.load_weight(self.model_ianet, './IANet_335.pth')\n",
        "        self.load_weight(self.model_nsnet, './NSNet_422.pth')\n",
        "        self.load_weight(self.model_canet, './FuseNet_CA_MEF_251.pth')\n",
        "\n",
        "    def load_weight(self, model, weight_pth):\n",
        "        if model is not None:\n",
        "            state_dict = torch.load(weight_pth)\n",
        "            ret = model.load_state_dict(state_dict, strict=True)\n",
        "            print(ret)\n",
        "\n",
        "    def noise_syn_exp(self, illumi, strength):\n",
        "        return torch.exp(-illumi) * strength\n",
        "\n",
        "    def forward(self, image, gamma=1., strength=0.1):\n",
        "        # Color space mapping\n",
        "        texture_in, cb_in, cr_in = torch.split(kornia.color.rgb_to_ycbcr(image), 1, dim=1)\n",
        "\n",
        "        # Illumination prediction\n",
        "        texture_in_down = F.interpolate(texture_in, scale_factor=0.5, mode='bicubic', align_corners=True)\n",
        "        texture_illumi = self.model_ianet(texture_in_down)\n",
        "        texture_illumi = F.interpolate(texture_illumi, scale_factor=2, mode='bicubic', align_corners=True)\n",
        "\n",
        "        # Illumination adjustment\n",
        "        texture_illumi = torch.clamp(texture_illumi ** gamma, 0., 1.)\n",
        "        texture_ia = texture_in / torch.clamp_min(texture_illumi, self.eps)\n",
        "        texture_ia = torch.clamp(texture_ia, 0., 1.)\n",
        "\n",
        "        # Noise suppression and fusion\n",
        "        attention = self.noise_syn_exp(texture_illumi, strength)\n",
        "        texture_res = self.model_nsnet(torch.cat([texture_ia, attention], dim=1))\n",
        "        texture_ns = texture_ia + texture_res\n",
        "\n",
        "        # Further preserve the texture under brighter illumination\n",
        "        texture_ns = texture_illumi * texture_in + (1 - texture_illumi) * texture_ns\n",
        "        texture_ns = torch.clamp(texture_ns, 0, 1)\n",
        "\n",
        "        # Color adaption\n",
        "        colors = self.model_canet(\n",
        "            torch.cat([texture_in, cb_in, cr_in, texture_ns], dim=1))\n",
        "        cb_out, cr_out = torch.split(colors, 1, dim=1)\n",
        "        cb_out = torch.clamp(cb_out, 0, 1)\n",
        "        cr_out = torch.clamp(cr_out, 0, 1)\n",
        "\n",
        "        # Color space mapping\n",
        "        image_out = kornia.color.ycbcr_to_rgb(\n",
        "            torch.cat([texture_ns, cb_out, cr_out], dim=1))\n",
        "\n",
        "        # Further preserve the color under brighter illumination\n",
        "        img_fusion = texture_illumi * image + (1 - texture_illumi) * image_out\n",
        "        _, cb_fuse, cr_fuse = torch.split(kornia.color.rgb_to_ycbcr(img_fusion), 1, dim=1)\n",
        "        image_out = kornia.color.ycbcr_to_rgb(\n",
        "            torch.cat([texture_ns, cb_fuse, cr_fuse], dim=1))\n",
        "        image_out = torch.clamp(image_out, 0, 1)\n",
        "\n",
        "        # outputs: texture_ia, texture_ns, image_out, texture_illumi, texture_res\n",
        "        return image_out\n",
        "\n",
        "model = ModelBreadNet().eval().cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGkRpq8N4Xn_",
        "outputId": "3c89cd6d-6620-4f38-d3a3-8d3055367a82"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<All keys matched successfully>\n",
            "<All keys matched successfully>\n",
            "<All keys matched successfully>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX変換"
      ],
      "metadata": {
        "id": "23sPlz6niw3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_onnx(net, file_name='output.onnx', input_shape=(512, 512), device='cpu'):\n",
        "    input_image = torch.randn(1, 3, input_shape[1], input_shape[0]).to(device)\n",
        "    gamma = 1.0\n",
        "    strength = 0.1\n",
        "\n",
        "    input_layer_names = ['input_image', 'gamma', 'strength']\n",
        "    output_layer_names = ['output_image']\n",
        "\n",
        "    torch.onnx.export(\n",
        "        net, \n",
        "        (input_image, gamma, strength),\n",
        "        file_name, \n",
        "        verbose=True,\n",
        "        opset_version=13,\n",
        "    )"
      ],
      "metadata": {
        "id": "fRFGW24rPskc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_onnx(model, file_name='Bread_320x240.onnx', input_shape=(320, 240), device='cuda:0')\n",
        "convert_to_onnx(model, file_name='Bread_640x360.onnx', input_shape=(640, 360), device='cuda:0')\n",
        "convert_to_onnx(model, file_name='Bread_416x416.onnx', input_shape=(416, 416), device='cuda:0')\n",
        "convert_to_onnx(model, file_name='Bread_512x512.onnx', input_shape=(512, 512), device='cuda:0')"
      ],
      "metadata": {
        "id": "SHM98L2kPsiE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}